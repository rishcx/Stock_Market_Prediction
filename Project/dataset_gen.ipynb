{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer\n",
    "from urllib.parse import unquote\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_article(url):\n",
    "    headers = {\n",
    "    'User-Agent': 'Your User Agent String',\n",
    "    }\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.text,'html.parser')\n",
    "    paragraphs=soup.find_all('p')\n",
    "    text= [paragraph.text for paragraph in paragraphs]\n",
    "    words=' '.join(text).split(' ')\n",
    "    article = ' '.join(words)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_news_url(keyword, start_date, end_date):\n",
    "    root = \"https://www.google.com/\"\n",
    "    search_query = keyword.replace(\" \", \"+\")\n",
    "    link = f\"{root}search?q={search_query}&tbm=nws&tbs=cdr:1,cd_min:{start_date},cd_max:{end_date}\"\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "    response = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    news_links = []\n",
    "\n",
    "    for article in soup.select('div.SoaBEf'):\n",
    "        link = article.select_one('a')\n",
    "        if link and 'href' in link.attrs:\n",
    "            url = link['href']\n",
    "            if url.startswith('/url?q='):\n",
    "                url = unquote(url.split('/url?q=')[1].split('&sa=')[0])\n",
    "            news_links.append(url)\n",
    "\n",
    "    return news_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    docs=text_splitter.split_text(data)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(tokenizer, model, text, max_chunk_length, summary_max_length):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_chunk_length, truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=summary_max_length, min_length=200, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(tokenizer,model,url):\n",
    "    data = scraping_article(url)\n",
    "    chunks = to_chunks(data)\n",
    "    # tokenizer, model=load_pegasus_model(\"google/pegasus-xsum\")\n",
    "    # tokenizer, model = load_bart_model(model_name)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        chunk_text = chunk\n",
    "        summary = summarize_text(tokenizer, model, chunk_text,3000,800)\n",
    "        summaries.append(summary)\n",
    "    concatenated_summaries = \" \".join(summaries)\n",
    "    #  Second summarization pass: Summarize the concatenated summaries\n",
    "    intermediate_chunks = [concatenated_summaries[i:i+3000] for i in range(0, len(concatenated_summaries), 3000)]\n",
    "    final_summaries = []\n",
    "    for intermediate_chunk in intermediate_chunks:\n",
    "        final_summary = summarize_text(tokenizer, model, intermediate_chunk,3000,800)\n",
    "        final_summaries.append(final_summary)\n",
    "    final_summary_text = \" \".join(final_summaries)\n",
    "    return final_summary_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.livemint.com/market/stock-market-news/tesla-share-price-falls-37-in-2024-so-far-market-value-drops-below-500-billion-11713325547711.html\n"
     ]
    }
   ],
   "source": [
    "print(find_news_url('tesla',\"04/17/2024\",\"04/17/2024\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla share price extended fall for 2024, pushing its market valuation briefly below $500 billion. Tesla stock price ended 2.7% lower at $157.11 on Tuesday in New York, after hitting a low of $153.75 during the session. Tesla shares have fallen 37% this year so far, becoming the second-biggest decliner on the S&P 500 Index in 2024. The fading interest from consumers, which is plaguing EV makers globally, is a more dire scenario for Tesla shares than for other carmakers. However, Musk himself has said the company will be “worth basically zero\" unless it can solve the problem of self-driving cars. The electric vehicle (EV) manufacturer reported first-quarter sales significantly below analysts’ expectations, raising concerns about Tesla’s growth trajectory, which were exacerbated by news that the company intends to scrap plans to make a cheaper EV and focus on building a so-called robotaxi instead, the Bloomberg report added.\n",
      "\n",
      "Use the weekly Newsquiz to test your knowledge of stories you saw on CNN.com. Today's quiz includes questions about our most popular stories of the week. Visit CNN.Com/Newsquiz each week for a chance to win a trip to see some of the world's most beautiful places. Visit CNN.com/NewsQuiz every Thursday for a new gallery of photos. Each week, we'll feature a different gallery of images from around the globe. Please submit your best photos of the U.S. and around the world for next week's Newsquizz. Click here to answer your questions. Back to the page you came from. Â  This week we asked you to share your favorite stories from CNN iReport. Send your photos and videos to iReport@cnn.co.uk. We'll feature the best in next week’s Newsqu quiz.   We'll also feature some of our favorite videos from the past week.\n",
      "\n",
      "The Bureau of Investment Promotion is learnt to have suggested the Bhiwadi industrial town as the location to Tesla. Other states in the fray include Gujarat, Tamil Nadu and Maharashtra. Musk will be on a two-day visit to India on April 21 and 22 and would be meeting Prime Minister Narendra Modi. He is also expected to announce some major decisions regarding Tesla and his Starlink internet service. India recently introduced an EV policy to incentivise electric vehicle companies to establish manufacturing facilities within the country. Under this policy, taxes on EV imports to India will be reduced from as high as 100% to just 15% if automakers invest a minimum of $1.5 Bn. The plant, which will likely come up in the next two years, will produce EVs for domestic and global markets. Meanwhile, the company has already commenced production of right-hand drive cars at its plant in Germany. The company is said to be eyeing potential locations for the showrooms at high street and mall sites.\n",
      "\n",
      "Tesla chief Elon Musk will be on a two-day visit to India over the weekend, on April 21 and 22. The billionaire is scheduled to meet Prime Minister Narendra Modi, and is also expected to announce some major decisions regarding Tesla and his Starlink internet service. Rajasthan is the latest in a growing list of states looking to woo Tesla, which is scouting for a location for its India operations. Reports suggest that Tesla may invest up to $3 billion and set up a factory to manufacture entry-level electric cars locally. In March, the government slashed the import tax on some EV models to 15 percent from 100 percent, giving Tesla an incentive to manufacture locally. More than half of Tesla’s global production takes place in China, and if Tesla decides to start manufacturing in India, it may relocate part of its supplies to India. The EV maker is reportedly sourcing anywhere between $1-2 billion worth of auto parts from India currently. Industry experts believe that since the Musk-led company is dependent on the Far East and Western Europe for imports and exports, port access time may play a major role in the company's decision. 07/1208/1110/1108/1209/1008/1009/1211/1011/0605/090/11/02/1112/091/1103/1113/1104/1114/1102/1010/097/11111/11000/11001/111200/11100/11011/111000/11101/11110/11010/11090/11102/11018/11017/11200/11019/11012/11014/11003/11016/11015/11013/11203/11007/112012/112001/112011/ 1100/11201/11103/11006/11105/11107/11002/11143/11205/11008/11199/11106/11202/11204/11206/11207/11104/1119/11150/1120/11151/1122/11152/11208/ 11185/1121/11196/11222/11223/11233/11227/11183/11225/11229/11234/11236/1123/11226/11237/11228/11230/11215/1126/11235/11232/11175/1124/11231/1125/11238/11239/11250/11220/11253/11251/11263/11240/11245/11244/11255/11254/11246/11267/11259/11258/11261/11252/11262/11249/11264/11257/11273/11268/11300/11256/11269/1127/11270/11271/11272/11247/11274/11275/11265/11296/11266/11278/1128/11299/11286/1129/11303/11287/11298/11307/11306/11309/11297/11304/11305/11312/11281/11325/11308/11313/11337/11295/11301/ 11333/11\n",
      "\n",
      "The electric vehicle pioneer is scrambling to set up plush showrooms and service hubs in big cities. The Indian government has been keen on wooing Tesla’s chief, Elon Musk. Negotiations for the car maker had, however, hit a wall as the completely-built units it wanted to import attracted 70-100 percent duty, which would make the cars unaffordable. The policy now allows imports at a knocked down duty of 15 percent on vehicles costing $35,000 and above, as long as the importer invests half a billion dollars in setting up manufacturing facilities in India. This is the first time auto investment has been linked to concessional imports. The government has tried to protect Indian auto companies in the economy segment; but in the premium class there are competitive global models from Volkswagen and Polestar to BYD that should also have easier entry, it has been said. It is hoped that the policy will also pave the way for the entry of other global brands like Audi and Mercedes-Benz.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m      2\u001b[0m     url\u001b[38;5;241m=\u001b[39mfind_news_url(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesla\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m04/17/2024\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m04/17/2024\u001b[39m\u001b[38;5;124m\"\u001b[39m)[i]\n\u001b[1;32m----> 3\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_article\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(summary)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m, in \u001b[0;36msummarize_article\u001b[1;34m(tokenizer, model, url)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m      8\u001b[0m     chunk_text \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m----> 9\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_text\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n\u001b[0;32m     11\u001b[0m concatenated_summaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(summaries)\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36msummarize_text\u001b[1;34m(tokenizer, model, text, max_chunk_length, summary_max_length)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize_text\u001b[39m(tokenizer, model, text, max_chunk_length, summary_max_length):\n\u001b[0;32m      2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39mmax_chunk_length, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m     summary_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_max_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     summary \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(summary_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summary\n",
      "File \u001b[1;32mc:\\Users\\utkar\\Desktop\\DG_liger\\Project\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\utkar\\Desktop\\DG_liger\\Project\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1795\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1787\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1788\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1789\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   1790\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1791\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1792\u001b[0m     )\n\u001b[0;32m   1794\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[1;32m-> 1795\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1804\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   1807\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   1808\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   1809\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1810\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1816\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   1817\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\utkar\\Desktop\\DG_liger\\Project\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2670\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m   2666\u001b[0m next_token_scores \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(\n\u001b[0;32m   2667\u001b[0m     next_token_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2668\u001b[0m )  \u001b[38;5;66;03m# (batch_size * num_beams, vocab_size)\u001b[39;00m\n\u001b[1;32m-> 2670\u001b[0m next_token_scores_processed \u001b[38;5;241m=\u001b[39m \u001b[43mlogits_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_token_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_sample:\n\u001b[0;32m   2672\u001b[0m     next_token_scores_processed \u001b[38;5;241m=\u001b[39m logits_warper(input_ids, next_token_scores_processed)\n",
      "File \u001b[1;32mc:\\Users\\utkar\\Desktop\\DG_liger\\Project\\venv\\Lib\\site-packages\\transformers\\generation\\logits_process.py:98\u001b[0m, in \u001b[0;36mLogitsProcessorList.__call__\u001b[1;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m         scores \u001b[38;5;241m=\u001b[39m processor(input_ids, scores, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\utkar\\Desktop\\DG_liger\\Project\\venv\\Lib\\site-packages\\transformers\\generation\\logits_process.py:159\u001b[0m, in \u001b[0;36mMinLengthLogitsProcessor.__call__\u001b[1;34m(self, input_ids, scores)\u001b[0m\n\u001b[0;32m    157\u001b[0m scores_processed \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_length:\n\u001b[1;32m--> 159\u001b[0m     scores_processed \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43meos_token_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores_processed\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    url=find_news_url('tesla',\"04/17/2024\",\"04/17/2024\")[i]\n",
    "    summary = summarize_article(tokenizer,model,url)\n",
    "    print(summary)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock details for tsla from 01-08-2023 to 03-01-2024:\n",
      "           Date    Open    High     Low   Close     Volume  Dividends  \\\n",
      "0    01-08-2023  266.26  266.47  260.25  261.07   83166000        0.0   \n",
      "1    02-08-2023  255.57  259.52  250.49  254.11  101752900        0.0   \n",
      "2    03-08-2023  252.04  260.49  252.00  259.32   97569100        0.0   \n",
      "3    04-08-2023  260.97  264.77  253.11  253.86   99242600        0.0   \n",
      "4    07-08-2023  251.45  253.65  242.76  251.45  111097900        0.0   \n",
      "..          ...     ...     ...     ...     ...        ...        ...   \n",
      "102  26-12-2023  254.49  257.97  252.91  256.61   86892400        0.0   \n",
      "103  27-12-2023  258.35  263.34  257.52  261.44  106494400        0.0   \n",
      "104  28-12-2023  263.66  265.13  252.71  253.18  113619900        0.0   \n",
      "105  29-12-2023  255.10  255.19  247.43  248.48  100615300        0.0   \n",
      "106  02-01-2024  250.08  251.25  244.41  248.42  104654200        0.0   \n",
      "\n",
      "     Stock Splits  \n",
      "0             0.0  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             0.0  \n",
      "4             0.0  \n",
      "..            ...  \n",
      "102           0.0  \n",
      "103           0.0  \n",
      "104           0.0  \n",
      "105           0.0  \n",
      "106           0.0  \n",
      "\n",
      "[107 rows x 8 columns]\n",
      "\n",
      "Current stock info:\n",
      "Current Price: 187.35\n",
      "52 Week High: 299.29\n",
      "52 Week Low: 138.8\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def get_stock_details(ticker, start_date, end_date):\n",
    "    # Create a Ticker object\n",
    "    stock = yf.Ticker(ticker)\n",
    "    \n",
    "    # Convert dates to the format required by yfinance (YYYY-MM-DD)\n",
    "    start_date_yf = datetime.strptime(start_date, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
    "    end_date_yf = datetime.strptime(end_date, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Fetch the historical data\n",
    "    hist = stock.history(start=start_date_yf, end=end_date_yf)\n",
    "    \n",
    "    # Convert to DataFrame and reset index to make Date a column\n",
    "    df = hist.reset_index()\n",
    "    \n",
    "    # Convert Date to DD-MM-YYYY format\n",
    "    df['Date'] = df['Date'].dt.strftime('%d-%m-%Y')\n",
    "    \n",
    "    # Round all float columns to 2 decimal places\n",
    "    float_columns = df.select_dtypes(include=['float64']).columns\n",
    "    df[float_columns] = df[float_columns].round(2)\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(f\"Stock details for {ticker} from {start_date} to {end_date}:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Print some current stock info\n",
    "    print(\"\\nCurrent stock info:\")\n",
    "    current_price = stock.info.get('currentPrice', 'N/A')\n",
    "    week_high = stock.info.get('fiftyTwoWeekHigh', 'N/A')\n",
    "    week_low = stock.info.get('fiftyTwoWeekLow', 'N/A')\n",
    "    \n",
    "    if isinstance(current_price, float):\n",
    "        current_price = round(current_price, 2)\n",
    "    if isinstance(week_high, float):\n",
    "        week_high = round(week_high, 2)\n",
    "    if isinstance(week_low, float):\n",
    "        week_low = round(week_low, 2)\n",
    "    \n",
    "    print(f\"Current Price: {current_price}\")\n",
    "    print(f\"52 Week High: {week_high}\")\n",
    "    print(f\"52 Week Low: {week_low}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Set the stock ticker symbol\n",
    "ticker_symbol = \"tsla\"  # Example: Apple Inc.\n",
    "\n",
    "# Set the date range\n",
    "start_date = \"01-08-2023\"\n",
    "end_date = \"03-01-2024\"\n",
    "\n",
    "# Call the function and get the DataFrame\n",
    "df = get_stock_details(ticker_symbol, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"new1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
