{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_texts=\"\"\"Giant stone head resembling an ancient Indigenous sculpture sits on top of a crushed Tesla car. Look what I do to your lousy car with this wonderful head. This is bigger than you and the rampant technologies, the sculptor says. A video released by the Colima 71 hotel shows the moment when the head was released and the car's roof gradually caved in. We wanted to preserve the magic and mystery of how it arrived, to let the work itself generate an impact and spark conversations, the hotel's artistic director says. It's the wonderful thing about art, it allows you these atrocities, says the 42-year-old sculptor. The head was inspired by the colossal head carvings of the Olmec, considered the first known major Mesoamerican civilization. The electric carmaker announced plans to build a huge factory in northern Mexico a year after announcing plans to sell cars in the U.S. and China.. The car's batteries had been removed before its roof was crushed.\n",
    "” \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from textblob import TextBlob\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.052, 'neu': 0.845, 'pos': 0.103, 'compound': 0.8338}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "sia=SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(news_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0647918  0.35041124 0.58479697]\n"
     ]
    }
   ],
   "source": [
    "encoded=tokenizer(news_texts,return_tensors='pt')\n",
    "output=model(**encoded)\n",
    "scores=output[0][0].detach().numpy()\n",
    "scores=softmax(scores)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound score: 0.5200051665306091\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'neg': -1,\n",
    "    'neu': 0,\n",
    "    'pos': 1\n",
    "}\n",
    "probabilities = {\n",
    "    'neg': scores[0],\n",
    "    'neu': scores[1],\n",
    "    'pos': scores[2]\n",
    "}\n",
    "compound_score = sum(probabilities[label] * weights[label] for label in probabilities)\n",
    "print(f\"Compound score: {compound_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=elon+musk&tbs=cdr%3A1%2Ccd_min%3A6%2F8%2F2023%2Ccd_max%3A6%2F8%2F2023&tbm=nws\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def find_url(keyword):\n",
    "    # Convert dates to the format Google expects (M/D/YYYY)\n",
    "    start_date = \"6/8/2023\"\n",
    "    end_date = \"6/8/2023\"\n",
    "\n",
    "    search_query = keyword.replace(\" \", \"+\")\n",
    "    # Construct the URL with the tbs parameter for date range\n",
    "    link = f\"https://www.google.com/search?q={search_query}&tbs=cdr%3A1%2Ccd_min%3A{start_date[0]}%2F{start_date[2]}%2F{start_date[4:]}%2Ccd_max%3A{start_date[0]}%2F{start_date[2]}%2F{start_date[4:]}&tbm=nws\"\n",
    "    print(link)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(link, headers=headers)\n",
    "    webpage = response.content\n",
    "    soup = BeautifulSoup(webpage, 'html5lib')\n",
    "    links = []\n",
    "    for div_tag in soup.find_all('div', class_='Gx5Zad'):\n",
    "        a_tag = div_tag.find('a')\n",
    "        if a_tag and 'href' in a_tag.attrs:\n",
    "            href = a_tag['href']\n",
    "            if href.startswith('/url?q='):\n",
    "                url = href.split('/url?q=')[1].split('&sa=')[0]\n",
    "                links.append(url)\n",
    "    return links\n",
    "\n",
    "# Example usage\n",
    "keyword = \"elon musk\"\n",
    "start_date = \"2024-06-04\"\n",
    "end_date = \"2024-06-04\"\n",
    "urls = find_url(keyword)\n",
    "for url in urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(keyword):\n",
    "    start_date = \"6/8/2023\"    \n",
    "    root = \"https://www.google.com/\"\n",
    "    search_query = keyword.replace(\" \", \"+\")\n",
    "    link = f\"https://www.google.com/search?q={search_query}&tbs=cdr%3A1%2Ccd_min%3A{start_date[0]}%2F{start_date[2]}%2F{start_date[4:]}%2Ccd_max%3A{start_date[0]}%2F{start_date[2]}%2F{start_date[4:]}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(link, headers=headers)\n",
    "    webpage = response.content\n",
    "    soup = BeautifulSoup(webpage, 'html5lib')\n",
    "    links = []\n",
    "    # print(soup.find_all('div'))\n",
    "    # print(link)\n",
    "    \n",
    "    for div_tag in soup.find_all('div', class_='Gx5Zad'):\n",
    "        a_tag = div_tag.find('a')\n",
    "        if a_tag:\n",
    "            if 'href' in a_tag.attrs:\n",
    "                href = a_tag['href']\n",
    "                if href.startswith('/url?q='):\n",
    "                    url = href.split('/url?q=')[1].split('&sa=')[0]\n",
    "                    links.append(url)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=elon+musk+news&tbs=cdr%3A1%2Ccd_min%3A6%2F8%2F2023%2Ccd_max%3A6%2F8%2F2023\n"
     ]
    }
   ],
   "source": [
    "a=find_url(\"elon musk news\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs:\n",
      "https://www.cnbc.com/2024/06/17/-wealth-manager-for-the-ultra-rich-names-3-global-stocks-to-buy-.html?__source=newsletter%7Cmsemea\n",
      "https://www.businesstoday.in/india/story/west-bengal-kanchanjunga-express-train-derailed-by-goods-train-in-bengals-siliguri-no-deaths-reported-so-far-mamata-banerjee-433512-2024-06-17\n",
      "https://www.hindustantimes.com/business/zepto-to-diversify-from-groceries-into-higher-value-items-looks-to-set-up-bigger-outlets-101718617108573.html\n",
      "https://www.rediff.com/business/report/sebi-signals-change-with-tougher-futures-and-options-stock-rules/20240617.htm\n",
      "https://fuelcellsworks.com/news/essar-group-commits-rs-30000-crore-3-6-billion-to-pioneer-green-and-blue-hydrogen-projects-across-global-operations/?utm_source=rss&utm_medium=rss&utm_campaign=essar-group-commits-rs-30000-crore-3-6-billion-to-pioneer-green-and-blue-hydrogen-projects-across-global-operations\n",
      "https://www.rediff.com/business/report/modi-30-railways-to-begin-hiring-again/20240617.htm\n",
      "https://www.rediff.com/business/report/modi-30-what-will-keep-nirmalaji-busy-this-year/20240617.htm\n",
      "https://www.indiaretailing.com/2024/06/17/spanish-perfume-maker-eurofragance-enters-india/\n",
      "https://x.com/ANI/status/1802688238328713307\n",
      "https://www.latestly.com/india/news/west-bengal-assembly-by-elections-2024-bjp-announces-candidates-for-bypolls-to-four-seats-in-state-check-names-of-candidates-6043898.html\n",
      "10 items total, printing the first one:\n",
      "Skip Navigation\n",
      " * watch live\n",
      " Markets\n",
      " Business\n",
      " Investing\n",
      " Tech\n",
      " Politics\n",
      " CNBC TV\n",
      " Watchlist\n",
      " Menu\n",
      " * Make It\n",
      " * select\n",
      " + ALL SELECT\n",
      "\n",
      "+ Credit Cards\n",
      "\n",
      "+ Loans\n",
      "\n",
      "+ Banking\n",
      "\n",
      "+ Mortgages\n",
      "\n",
      "+ Insurance\n",
      "\n",
      "+ Credit Monitoring\n",
      "\n",
      "+ Personal Finance\n",
      "\n",
      "+ Small Business\n",
      "\n",
      "+ Taxes\n",
      "\n",
      "+ Help for Low Credit Scores\n",
      "\n",
      "+ Investing\n",
      "\n",
      "Credit CardsLoansBankingMortgagesInsuranceCredit MonitoringPersonal FinanceSmall BusinessTaxesHelp for Low Credit ScoresInvesting\n",
      " * USA\n",
      " * INTL\n",
      " * watch live\n",
      " Search quotes, news & videos\n",
      " Watchlist\n",
      " SIGN IN\n",
      " Markets\n",
      " Business\n",
      " Investing\n",
      " Tech\n",
      " Politics\n",
      " CNBC TV\n",
      " Watchlist\n",
      " Menu\n",
      "\n",
      "Forget Nvidia: Wealth manager for the ultra-rich names 3 global stocks to buy instead\n",
      "\n",
      "Published Sun, Jun 16 20247:20 PM EDT\n",
      " Amala Balakrishner@in/amala-balakrishner@_amalabk\n",
      " WATCH LIVE\n",
      " After a boom of interest in chipmaker Nvidia — with shares logging an astronomical 200% rise over the last 12 months — investors appear divided on whether to buy into the stock . One wealth manager, however, is happy not owning the chipmaker. \"I bought into Nvidia during early days and exited my position at a decent 300% gain. Of course, the stock has risen further to over $1,000 now, but I'm glad to have secured a profit at a price point I'm happy with,\" Dhruba Jyoti Sengupta told CNBC Pro earlier this month. The CEO of Wrise Private Middle East, which serves ultra-high-net-worth and high-net-worth individuals across Asia, the Middle East and Europe, said he likes three different stocks from around the world instead. Adobe Top of Sengupta's list is Adobe . After a tough time earlier in the year, the stock is seeing renewed interest following its second-quarter earnings which surpassed analysts' expectations. Shares in Adobe jumped by 17% after its results announcement last week, and are up around 7% in the last 12 months. Sengupta sees promise in the software company given the potential of generative AI not just for text, but also photos in the medium to longer-term. \"The market is not seeing much potential in Adobe because Nvidia is making all these big future predictions and markets love that. But Adobe offers a great opportunity being the biggest software company for photos,\" he added. According to FactSet data, of 43 analysts covering the stock, 34 give it a buy or overweight rating, 7 have hold ratings while two have a sell call. Their average price target is $611.20, giving it 16.3% potential upside. Harley-Davidson In the luxury goods space, Sengupta has his eye on Harley Davidson . \"Living in Dubai, I am a firm believer that no matter what happens, the luxury stocks in the long run will always do well ... Men are now becoming like women in terms of the luxury spends, especially on toys like Harley Davidson,\" he said. Shares in the iconic motorcycle manufacturer are down nearly 6% over the last 12 months, but Sengupta says the stock is undervalued, making it a good time to buy. Of 17 analysts covering Harley-Davidson, 8 give it a buy or overweight rating, while 9 have a hold rating at an average price of $42.96, according to FactSet data. This gives it upside potential of 32.1%. HDFC Bank In India, the wealth manager is betting on financial firm HDFC , as the country — and the bank itself — prepares for growth. \"The bank has a hugely diversified revenue stream. I think [it's] the most valuable bank in the world right now,\" he said. When asked how HDFC compares with competitors like ICICI Bank , Sengupta responded that the former's management is \"very stable with consistent leadership and that puts them in good standing.\" HDFC trades on India's National Stock Exchange and the BSE, and as an ADR in the U.S. Its shares are also included in the Nifty India Financials ETF (15.6% weight) and iShares India 50 ETF (11.2%). Shares in the bank are up by just over 1% in the last 12 months, but are showing signs of picking up. Of 43 analysts covering HDFC Bank on FactSet, 38 have a buy or overweight rating on the stock at an average price target of 1,872.32 Indian rupees ($22.41), giving it upside potential of 17.2%.\n",
      "\n",
      "NEXT PRO TALK\n",
      "\n",
      "2 Days Remaining\n",
      " Wed, June 19 2024 - 1:30am\n",
      " Add To Calendar\n",
      " CNBC Pro Talks: Fund manager reveals how to invest after India's election\n",
      "\n",
      "More In Pro Stock Picks\n",
      "\n",
      "These stocks are an AI model's biggest upside picks after a week of mild economic data\n",
      " Jesse Pound\n",
      " Early bets on AI have helped this global tech fund outperform for a second year\n",
      " Samantha Subin\n",
      " 'I don't like Apple': Why one veteran portfolio manager is steering clear of the tech giant\n",
      " Amala Balakrishner\n",
      " Read More\n",
      " * \n",
      " * \n",
      " * \n",
      " * \n",
      " * \n",
      " * \n",
      " * \n",
      " * Subscribe to CNBC PRO\n",
      " * Subscribe to Investing Club\n",
      " * Licensing & Reprints\n",
      " * CNBC Councils\n",
      " * Select Personal Finance\n",
      " * CNBC on Peacock\n",
      " * Join the CNBC Panel\n",
      " * Supply Chain Values\n",
      " * Select Shopping\n",
      " * Closed Captioning\n",
      " * Digital Products\n",
      " * News Releases\n",
      " * Internships\n",
      " * Corrections\n",
      " * About CNBC\n",
      " * Ad Choices\n",
      " * Site Map\n",
      " * Podcasts\n",
      " * Careers\n",
      " * Help\n",
      " * Contact\n",
      "\n",
      "* News Tips\n",
      "\n",
      "Got a confidential news tip? We want to hear from you.\n",
      "\n",
      "Get In Touch\n",
      "\n",
      "* CNBC Newsletters\n",
      "\n",
      "Sign up for free newsletters and get more CNBC delivered to your inbox\n",
      "\n",
      "Sign Up Now\n",
      "\n",
      "Get this delivered to your inbox, and more info about our products and services.\n",
      "\n",
      "* Advertise With Us\n",
      "\n",
      "Please Contact Us\n",
      " * Privacy Policy\n",
      " * \n",
      " * CA Notice\n",
      " * Terms of Service\n",
      "\n",
      "© 2024 CNBC LLC. All Rights Reserved. A Division of NBCUniversal\n",
      "\n",
      "Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.\n",
      "\n",
      "Market Data Terms of Use and Disclaimers\n",
      "\n",
      "Data also provided by\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from exa_py import Exa\n",
    "\n",
    "exa = Exa(api_key=\"9fccb5a3-0bff-453b-93bf-dd7e82f7a690\")\n",
    "\n",
    "one_week_ago = (datetime.now() - timedelta(days=7))\n",
    "date_cutoff = one_week_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "search_query = \"hdfc news \"\n",
    "search_response = exa.search_and_contents(\n",
    "    search_query, use_autoprompt=True, start_published_date=date_cutoff,end_published_date=date_cutoff\n",
    ")\n",
    "\n",
    "urls = [result.url for result in search_response.results]\n",
    "print(\"URLs:\")\n",
    "for url in urls:\n",
    "    print(url)\n",
    "\n",
    "\n",
    "# result = exa.search_and_contents(\n",
    "#   \"HDFC stock latest news in a week\",\n",
    "#   type=\"neural\",\n",
    "#   use_autoprompt=True,\n",
    "#   num_results=10,\n",
    "#   text=True\n",
    "# )\n",
    "\n",
    "results = search_response.results\n",
    "result_item = results[0]\n",
    "print(f\"{len(results)} items total, printing the first one:\")\n",
    "print(result_item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import unquote\n",
    "\n",
    "def find_news_url(keyword, start_date, end_date):\n",
    "    root = \"https://www.google.com/\"\n",
    "    search_query = keyword.replace(\" \", \"+\")\n",
    "    link = f\"{root}search?q={search_query}&tbm=nws&tbs=cdr:1,cd_min:{start_date},cd_max:{end_date}\"\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    \n",
    "    response = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    news_links = []\n",
    "    \n",
    "    for article in soup.select('div.SoaBEf'):\n",
    "        link = article.select_one('a')\n",
    "        if link and 'href' in link.attrs:\n",
    "            url = link['href']\n",
    "            if url.startswith('/url?q='):\n",
    "                url = unquote(url.split('/url?q=')[1].split('&sa=')[0])\n",
    "            news_links.append(url)\n",
    "    \n",
    "    return news_links\n",
    "\n",
    "# Example usage\n",
    "keyword = \"elon musk\"\n",
    "start_date = \"6/8/2023\"\n",
    "end_date = \"6/8/2023\"\n",
    "results = find_news_url(keyword, start_date, end_date)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_article(url):\n",
    "    headers = {\n",
    "    'User-Agent': 'Your User Agent String',\n",
    "    }\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.text,'html.parser')\n",
    "    paragraphs=soup.find_all('p')\n",
    "    text= [paragraph.text for paragraph in paragraphs]\n",
    "    words=' '.join(text).split(' ')\n",
    "    article = ' '.join(words)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.motor1.com/news/702440/tesla-plaid-vs-dodge-demon-170-drag-race/\"\n",
    "a=scraping_article(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment for 'byd': Negative\n",
      "Sentiment score: -0.53\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load spaCy for text processing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load RoBERTa sentiment analysis model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"roberta-base\")\n",
    "\n",
    "def analyze_keyword_sentiment(text, keyword):\n",
    "    # Normalize text and keyword\n",
    "    text = text.lower()\n",
    "    keyword = keyword.lower()\n",
    "\n",
    "    # Check if keyword is in the text\n",
    "    if keyword not in text:\n",
    "        return \"Neutral (Keyword not found)\", 0\n",
    "\n",
    "    # Tokenize the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Find sentences containing the keyword\n",
    "    relevant_sentences = [sent.text for sent in doc.sents if keyword in sent.text.lower()]\n",
    "    \n",
    "    if not relevant_sentences:\n",
    "        return \"Neutral (Keyword not in complete sentence)\", 0\n",
    "\n",
    "    # Analyze sentiment of relevant sentences\n",
    "    sentiments = [sentiment_analyzer(sent)[0] for sent in relevant_sentences]\n",
    "    \n",
    "    # Calculate weighted sentiment score\n",
    "    total_score = sum(sentiment['score'] if sentiment['label'] == 'POSITIVE' else -sentiment['score'] for sentiment in sentiments)\n",
    "    avg_score = total_score / len(sentiments)\n",
    "    \n",
    "    # Determine overall sentiment\n",
    "    if avg_score > 0.1:\n",
    "        label = \"Positive\"\n",
    "    elif avg_score < -0.1:\n",
    "        label = \"Negative\"\n",
    "    else:\n",
    "        label = \"Neutral\"\n",
    "\n",
    "    return label, avg_score\n",
    "\n",
    "# Example usage\n",
    "\n",
    "keyword = \"byd\"\n",
    "\n",
    "sentiment, score = analyze_keyword_sentiment(news_texts, keyword)\n",
    "print(f\"Sentiment for '{keyword}': {sentiment}\")\n",
    "print(f\"Sentiment score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
