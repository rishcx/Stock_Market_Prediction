{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_token=os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "os.environ['HF_TOKEN']=api_token\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_sector(stock_symbol):\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "        info = stock.info\n",
    "        sector = info.get('sector', 'Sector information not available')\n",
    "        industry=info.get('industry','Industry information not available')        \n",
    "        return sector,industry\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL\n",
      "Sector: Technology\n",
      "Industry: Consumer Electronics\n"
     ]
    }
   ],
   "source": [
    "stock_symbol = input(\"Enter Stock Symbol: \")\n",
    "sector,industry = get_stock_sector(stock_symbol)\n",
    "if sector and industry:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", sector)\n",
    "    print('Industry:',industry)\n",
    "elif sector:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", sector)\n",
    "    print('Industry:',\"Falied to retrive industry information\")\n",
    "elif industry:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", \"Failed to retrieve sector information.\")\n",
    "    print('Industry:',industry)   \n",
    "else:\n",
    "    print(\"Failed to retrieve sector information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_article(url):\n",
    "    headers = {\n",
    "    'User-Agent': 'Your User Agent String',\n",
    "    }\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.text,'html.parser')\n",
    "    paragraphs=soup.find_all('p')\n",
    "    text= [paragraph.text for paragraph in paragraphs]\n",
    "    words=' '.join(text).split(' ')\n",
    "    article = ' '.join(words)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(keyword):\n",
    "    \n",
    "    root = \"https://www.google.com/\"\n",
    "    search_query = keyword.replace(\" \", \"+\")\n",
    "    link = f\"https://www.google.com/search?q={search_query}&tbm=nws\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(link, headers=headers)\n",
    "    webpage = response.content\n",
    "    soup = BeautifulSoup(webpage, 'html5lib')\n",
    "    links = []\n",
    "    for div_tag in soup.find_all('div', class_='Gx5Zad'):\n",
    "        a_tag = div_tag.find('a')\n",
    "        if a_tag:\n",
    "            if 'href' in a_tag.attrs:\n",
    "                href = a_tag['href']\n",
    "                if href.startswith('/url?q='):\n",
    "                    url = href.split('/url?q=')[1].split('&sa=')[0]\n",
    "                    links.append(url)\n",
    "    return links    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    docs=text_splitter.split_text(data)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bart_model(model_name=\"facebook/bart-large-cnn\"):\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(tokenizer, model, text, max_chunk_length, summary_max_length):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_chunk_length, truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=summary_max_length, min_length=200, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(url, model_name=\"facebook/bart-large-cnn\"):\n",
    "    data = scraping_article(url)\n",
    "    chunks = to_chunks(data)\n",
    "    tokenizer, model = load_bart_model(model_name)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        chunk_text = chunk\n",
    "        summary = summarize_text(tokenizer, model, chunk_text,3000,800)\n",
    "        summaries.append(summary)\n",
    "    concatenated_summaries = \" \".join(summaries)\n",
    "    #  Second summarization pass: Summarize the concatenated summaries\n",
    "    intermediate_chunks = [concatenated_summaries[i:i+3000] for i in range(0, len(concatenated_summaries), 3000)]\n",
    "    final_summaries = []\n",
    "    for intermediate_chunk in intermediate_chunks:\n",
    "        final_summary = summarize_text(tokenizer, model, intermediate_chunk,3000,800)\n",
    "        final_summaries.append(final_summary)    \n",
    "    final_summary_text = \" \".join(final_summaries)    \n",
    "    return final_summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dubai Police in November 2019 hinted that it could add Tesla Cybertruck to its impressive fleet of cars. The police already included Bugattis, Aston Martins, and Porsches. Elon Musk, co-founder and CEO of Tesla, soon dropped a comment on the post. “This is awesome and should come as no surprise. Dubai makes wonderful decisions,’ wrote X user Cindys, while another called it “Smart and wise choice” “Awesome. Need them in Chicago,” said a third, while a fourth said it was “Fantastic seeing the powerful Dubai Police add Cybert truck! Elon Musk’s electric truck is going across the globe and joined the most innovative police force! Bravo!” joined a fifth individual. ” Combining cutting-edge technology with sustainability sets a great example for modern policing,“ posted X user Sheikh Aaqib Satar. ‘This is a great decision.\n"
     ]
    }
   ],
   "source": [
    "url=find_url('elon musk')[1]\n",
    "# url1=\"https://www.businesstoday.in/markets/company-stock/story/hdfc-bank-shares-negative-returns-in-2024-buy-sell-or-hold-price-targets-433552-2024-06-17\"\n",
    "summary = summarize_article(url)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_model(model_name=\"cardiffnlp/twitter-roberta-base-sentiment\"):\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    return tokenizer,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_senti(news_texts):\n",
    "    tokenizer,model=senti_model()\n",
    "    encoded=tokenizer(news_texts,return_tensors='pt')\n",
    "    output=model(**encoded)\n",
    "    scores=output[0][0].detach().numpy()\n",
    "    scores=softmax(scores)\n",
    "    weights = {\n",
    "        'neg': -1,\n",
    "        'neu': 0,\n",
    "        'pos': 1\n",
    "    }\n",
    "    probabilities = {\n",
    "        'neg': scores[0],\n",
    "        'neu': scores[1],\n",
    "        'pos': scores[2]\n",
    "    }\n",
    "    compound_score = sum(probabilities[label] * weights[label] for label in probabilities)\n",
    "    senti_dict={\n",
    "        'neg':scores[0],\n",
    "        'neu': scores[1],\n",
    "        'pos': scores[2],\n",
    "        'polarity':compound_score        \n",
    "    }\n",
    "    return senti_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utkar\\Desktop\\DG_liger\\Project\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0023002203, 'neu': 0.03798616, 'pos': 0.9597136, 'polarity': 0.9574133579153568}\n"
     ]
    }
   ],
   "source": [
    "print(find_senti(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.hindustantimes.com/trending/elon-musk-s-unmissable-reaction-to-dubai-police-s-addition-of-tesla-cybertruck-to-patrol-fleet-seen-it-yet-101718599827980.html\n"
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
