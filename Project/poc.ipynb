{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_sector(stock_symbol):\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "        info = stock.info\n",
    "        sector = info.get('sector', 'Sector information not available')\n",
    "        industry=info.get('industry','Industry information not available')        \n",
    "        return sector,industry\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL\n",
      "Sector: Technology\n",
      "Industry: Consumer Electronics\n"
     ]
    }
   ],
   "source": [
    "stock_symbol = input(\"Enter Stock Symbol: \")\n",
    "sector,industry = get_stock_sector(stock_symbol)\n",
    "if sector and industry:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", sector)\n",
    "    print('Industry:',industry)\n",
    "elif sector:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", sector)\n",
    "    print('Industry:',\"Falied to retrive industry information\")\n",
    "elif industry:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", \"Failed to retrieve sector information.\")\n",
    "    print('Industry:',industry)   \n",
    "else:\n",
    "    print(\"Failed to retrieve sector information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(url):\n",
    "    loader=UnstructuredURLLoader(urls=[\n",
    "    url,\n",
    "    ])\n",
    "    data=loader.load()\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    docs=text_splitter.split_documents(data)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=loading_data(\"https://www.bbc.com/articles/c4nnje9rpjgo\")\n",
    "# docs=to_chunks(data)\n",
    "# for doc in docs:\n",
    "#     print(len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_token=os.getenv('HUGGINGFACEHUB_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN']=api_token\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_distilbert_model(model_name=\"sshleifer/distilbart-cnn-12-6\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(tokenizer, model, text, max_chunk_length, summary_max_length):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_chunk_length, truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=summary_max_length, min_length=200, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(url, model_name=\"sshleifer/distilbart-cnn-12-6\"):\n",
    "    data = loading_data(url)\n",
    "    chunks = to_chunks(data)\n",
    "    tokenizer, model = load_distilbert_model(model_name)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        chunk_text = chunk.page_content\n",
    "        summary = summarize_text(tokenizer, model, chunk_text,3000,800)\n",
    "        summaries.append(summary)\n",
    "    concatenated_summaries = \" \".join(summaries)\n",
    "    #  Second summarization pass: Summarize the concatenated summaries\n",
    "    intermediate_chunks = [concatenated_summaries[i:i+3000] for i in range(0, len(concatenated_summaries), 3000)]\n",
    "    final_summaries = []\n",
    "    for intermediate_chunk in intermediate_chunks:\n",
    "        final_summary = summarize_text(tokenizer, model, intermediate_chunk,3000,800)\n",
    "        final_summaries.append(final_summary)\n",
    "    \n",
    "    final_summary_text = \" \".join(final_summaries)\n",
    "    \n",
    "    return final_summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Deal was blocked earlier this year by a judge in Delaware over concerns it was unfair to shareholders. Deal is worth an estimated 300 times what the top-earning boss in the US made last year. Mr Musk had campaigned fiercely for the payout, which is worth up to $56billion (£43.9bn) The compensation plan gives Mr Musk rights to roughly 300 million shares - the equivalent to a 10% stake in the firm - as a reward for Tesla meeting a number of goals set out in 2018 which are linked to sales, profits and the share price. The vote is not binding and legal experts say it is not clear if the court that blocked the deal will accept the re-vote and allow the company to restore the pay package. The firm's legal headquarters will now be moved to Texas. It has not yet been announced. GameStop raised $2billion in the first half of the company's annual $4bn annual profit run for the first time since 2008. Decision comes as an investigation continues into what the EU calls China’s ‘unfairly\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.bbc.com/news/articles/cleezyxjv4jo\"\n",
    "summary = summarize_article(url)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
