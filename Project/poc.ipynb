{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_sector(stock_symbol):\n",
    "    try:\n",
    "        stock = yf.Ticker(stock_symbol)\n",
    "        info = stock.info\n",
    "        sector = info.get('sector', 'Sector information not available')\n",
    "        industry=info.get('industry','Industry information not available')        \n",
    "        return sector,industry\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL\n",
      "Sector: Technology\n",
      "Industry: Consumer Electronics\n"
     ]
    }
   ],
   "source": [
    "stock_symbol = input(\"Enter Stock Symbol: \")\n",
    "sector,industry = get_stock_sector(stock_symbol)\n",
    "if sector and industry:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", sector)\n",
    "    print('Industry:',industry)\n",
    "elif sector:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", sector)\n",
    "    print('Industry:',\"Falied to retrive industry information\")\n",
    "elif industry:\n",
    "    print(\"Stock:\",stock_symbol)\n",
    "    print(\"Sector:\", \"Failed to retrieve sector information.\")\n",
    "    print('Industry:',industry)   \n",
    "else:\n",
    "    print(\"Failed to retrieve sector information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(url):\n",
    "    loader=UnstructuredURLLoader(urls=[\n",
    "    url,\n",
    "    ])\n",
    "    data=loader.load()\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_article(url):\n",
    "    headers = {\n",
    "    'User-Agent': 'Your User Agent String',\n",
    "    }\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.text,'html.parser')\n",
    "    paragraphs=soup.find_all('p')\n",
    "    text= [paragraph.text for paragraph in paragraphs]\n",
    "    words=' '.join(text).split(' ')\n",
    "    article = ' '.join(words)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(keyword):\n",
    "    \n",
    "    root = \"https://www.google.com/\"\n",
    "    search_query = keyword.replace(\" \", \"+\")\n",
    "    link = f\"https://www.google.com/search?q={search_query}&tbm=nws\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(link, headers=headers)\n",
    "    webpage = response.content\n",
    "    soup = BeautifulSoup(webpage, 'html5lib')\n",
    "    links = []\n",
    "    for div_tag in soup.find_all('div', class_='Gx5Zad'):\n",
    "        a_tag = div_tag.find('a')\n",
    "        if a_tag:\n",
    "            if 'href' in a_tag.attrs:\n",
    "                href = a_tag['href']\n",
    "                if href.startswith('/url?q='):\n",
    "                    url = href.split('/url?q=')[1].split('&sa=')[0]\n",
    "                    links.append(url)\n",
    "    return links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chunks(data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=3000,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    docs=text_splitter.split_text(data)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_token=os.getenv('HUGGINGFACEHUB_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN']=api_token\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_distilbert_model(model_name=\"sshleifer/distilbart-cnn-12-6\"):\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#     model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "#     return tokenizer, model\n",
    "\n",
    "def load_bart_model(model_name=\"facebook/bart-large-cnn\"):\n",
    "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(tokenizer, model, text, max_chunk_length, summary_max_length):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_chunk_length, truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=summary_max_length, min_length=200, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(url, model_name=\"facebook/bart-large-cnn\"):\n",
    "    data = scraping_article(url)\n",
    "    chunks = to_chunks(data)\n",
    "    tokenizer, model = load_bart_model(model_name)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        chunk_text = chunk\n",
    "        summary = summarize_text(tokenizer, model, chunk_text,3000,800)\n",
    "        summaries.append(summary)\n",
    "    concatenated_summaries = \" \".join(summaries)\n",
    "    #  Second summarization pass: Summarize the concatenated summaries\n",
    "    intermediate_chunks = [concatenated_summaries[i:i+3000] for i in range(0, len(concatenated_summaries), 3000)]\n",
    "    final_summaries = []\n",
    "    for intermediate_chunk in intermediate_chunks:\n",
    "        final_summary = summarize_text(tokenizer, model, intermediate_chunk,3000,800)\n",
    "        final_summaries.append(final_summary)\n",
    "    \n",
    "    final_summary_text = \" \".join(final_summaries)\n",
    "    \n",
    "    return final_summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Former Union minister Rajeev Chandrasekhar has pushed back against Elon Musk's comments on electronic voting machines (EVMs) Musk had suggested they should be eliminated due to the potential risk of being hacked by humans or AI, even if the risk is minimal. ChandraseKhar countered Muskâ€™s view, stating it might apply to the US and other regions where standard computing platforms are used to build \"Internet-connected voting machines\" He asserted that this is not the case in India, where EVMs are custom-designed, secure, and isolated from any network or media. The entrepreneur-turned-politician also offered to give a tutorial to the SpaceX boss demonstrating the robustness of EVMs designed in India. During the recently concluded marathon Lok Sabha election, the Opposition had alleged that there was a possibility of the ruling BJP tampering with EVM to turn poll outcomes in their favour. In response, Chief Election Commissioner RajeeV Kumar assured that EVM are \"100% safe\"\n"
     ]
    }
   ],
   "source": [
    "url=find_url('elon musk')[0]\n",
    "summary = summarize_article(url)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
